{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Regression의 결과를 확률로 나타내서 발생할 사건의 가능성을 표현하고자 하는 목적."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Odds Ratio : $\\frac{P(X)}{1-P(X)}$ \n",
    "  - 해당 사건이 일어날 확률과 일어나지 않을 확률의 비율\n",
    "- Logit function : $-\\log_{e}{(\\frac{1}{p}-1)}$\n",
    "  - Odds Ratio에 밑이 자연대수 $e$인 로그를 씌운 형태."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sigmoid function : $\\frac{1}{1+e^{-z}}$ (여기서 $z$는 $-\\log_{e}{(\\frac{1}{y}-1)}$)\n",
    "  - Logit function의 역함수\n",
    "  - 미분 가능한 연속구간으로 변환됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- weight 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hypothesis function : $h_{\\theta}(x)$ : $\\frac{1}{1+e^{-z}}$ = $\\frac{1}{1+e^{-\\theta^Tx}}$\n",
    "  - 사건이 발생할 확률을 의미함 (0과 1 사이의 값)\n",
    "- Cost function : $J(\\theta) = -\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}[y^{(i)}\\log{h_\\theta(x^{(i)})} + (1 - y^{(i)})\\log(1-h_\\theta(x^{(i)}))]$\n",
    "  - 정리하면 $-\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}{[y_i\\theta{x}^{(i)} - \\log(1+e^{\\theta{x}^{(i)}})]}$\n",
    "- Partial derivation of cost function : $\\frac{\\partial}{\\partial\\theta_j} = \\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}{(h_\\theta(x^i) - y^i)x_j^i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Weight update (Gradient Descent)\n",
    "  - $\\theta_j := \\theta_j - \\alpha\\frac{\\partial}{\\partial\\theta_j}$ = $\\theta_j - \\alpha\\displaystyle\\sum_{i=1}^{m}{(h_\\theta(x^i) - y^i)x_j^i}$\n",
    "  - 모든 $\\theta_j$ 를 동시에 업데이트해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code는 강의 영상(Part 9-4) 참고.\n",
    "- 데이터를 구할 수 code 작성은 생략"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c585f91d3623973be3accc48b0d5e967ce904a396a0f0c8bda7b100d8b60333f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
