{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "datasets = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = datasets[\"data\"]\n",
    "x_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = datasets[\"target\"]\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = y_data.reshape([-1,1])\n",
    "y_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y_data)\n",
    "y_data = enc.transform(y_data).toarray()\n",
    "y_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_data_minmax = min_max_scaler.fit_transform(x_data)\n",
    "x_data_minmax[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [1.        , 0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [1.        , 0.11111111, 0.5       , 0.05084746, 0.04166667]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0 = np.ones(x_data_minmax.shape[0])\n",
    "x_data_minmax = np.column_stack((x_0, x_data_minmax))\n",
    "\n",
    "x_data_minmax[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94414395, 0.30207917, 0.89048229, 0.64338334, 0.41383933],\n",
       "       [0.14859301, 0.62325635, 0.16024632, 0.119151  , 0.5300794 ],\n",
       "       [0.08860008, 0.82127508, 0.69798108, 0.74528909, 0.12224229]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.random.uniform(size = (3, 5))\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "  e = np.exp(z)\n",
    "  p = e / np.sum(np.exp(z), axis = 1).reshape([-1, 1])\n",
    "  return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.6286866 , 0.41741305, 0.76296533],\n",
       "        [1.42638728, 0.34940304, 0.57192621],\n",
       "        [1.47290716, 0.32611204, 0.57183289]]),\n",
       " (150, 3))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x_data_minmax.dot(weights.T)\n",
    "z[:3], z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58188057, 0.17329436, 0.24482507],\n",
       "       [0.56620856, 0.19286265, 0.24092879]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(z[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_function(y, x, weights):\n",
    "  z = x_data_minmax.dot(weights.T)\n",
    "  result = -np.sum(\n",
    "             np.sum(\n",
    "              (y * np.log(softmax(z))), axis = 1).reshape((-1,1))\n",
    "             )\n",
    "  return result # 상수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audioop import cross\n",
    "\n",
    "\n",
    "def minimize_gradient(y, x, initial_weights, iterations = 500000, alpha = 0.001):\n",
    "  cost_history = []\n",
    "  theta_history = []\n",
    "  m = y.shape[0]\n",
    "  theta = np.copy(initial_weights)\n",
    "\n",
    "  number_of_classes = theta.shape[0]\n",
    "  number_of_weights = theta.shape[1]\n",
    "\n",
    "  for _ in range(iterations):\n",
    "    original_theta = np.copy(theta)\n",
    "    for k in range(number_of_classes):\n",
    "      for j in range(number_of_weights):\n",
    "        partial_x = x[:, j]\n",
    "        partial_entropy = y - softmax(x.dot(original_theta.T))\n",
    "        theta[k][j] = original_theta[k][j] + (alpha * partial_entropy[:, k].dot(partial_x.T)) / 150\n",
    "    \n",
    "    if (_ % 10000) == 0:\n",
    "      print(cross_entropy_function(y, x, theta) / 150)\n",
    "      cost_history.append(cross_entropy_function(y, x, theta))\n",
    "  \n",
    "  return theta, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1894210677880528\n",
      "0.7172846225460702\n",
      "0.596598220225385\n",
      "0.5288309340388052\n",
      "0.48390221002720374\n",
      "0.45097370781978935\n",
      "0.42524683341127\n",
      "0.404256840124628\n",
      "0.3865941502905619\n",
      "0.37138569324128334\n",
      "0.3580567812269285\n",
      "0.3462107003616247\n",
      "0.33556296546415026\n",
      "0.3259031219731775\n",
      "0.31707139243037036\n",
      "0.3089437808727984\n",
      "0.30142222737353397\n",
      "0.2944279003142669\n",
      "0.28789650572397485\n",
      "0.28177493199297127\n",
      "0.2760188016100256\n",
      "0.27059065299892926\n",
      "0.2654585688870339\n",
      "0.26059512678988433\n",
      "0.2559765855995676\n",
      "0.2515822477466811\n",
      "0.24739395364882577\n",
      "0.24339567703465315\n",
      "0.2395731980446635\n",
      "0.23591383691360052\n",
      "0.232406235289005\n",
      "0.229040175337735\n",
      "0.2258064290754867\n",
      "0.2226966320554574\n",
      "0.21970317683231444\n",
      "0.21681912258963715\n",
      "0.2140381180636634\n",
      "0.2113543354711537\n",
      "0.20876241359671055\n",
      "0.2062574085456441\n",
      "0.20383475094528333\n",
      "0.20149020859756797\n",
      "0.19921985376147744\n",
      "0.1970200343851565\n",
      "0.1948873487218472\n",
      "0.19281862285653395\n",
      "0.1908108907460882\n",
      "0.1888613764379136\n",
      "0.18696747818345708\n",
      "0.18512675420544944\n"
     ]
    }
   ],
   "source": [
    "theta, cost_history = minimize_gradient(y_data, x_data_minmax, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_index = np.random.randint(0, 150, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 2, 1, 2, 0, 1, 1, 1, 1, 0, 1, 0, 0, 2, 1, 1, 1, 2, 2,\n",
       "       2, 1, 2, 0, 0, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(softmax(x_data_minmax[rand_index].dot(theta.T)), axis = 1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 2, 1, 2, 0, 1, 1, 1, 1, 0, 1, 0, 0, 2, 2, 1, 1, 2, 2,\n",
       "       2, 1, 2, 0, 0, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.argmax(y_data[rand_index], axis = 1)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred == y_true) / len(rand_index) # Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for Multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy : 전체 class 중 정확히 일치한 class의 개수\n",
    "- Precision : TP / (TP + FP) (= 실제P / 예측P)\n",
    "  - ex) Precision A = A라고 예측한 것들 중 실제 A인 것의 비율\n",
    "  - macro 방식 : 클래스별로 Precision을 구해서 평균을 낸 것.\n",
    "  - micro 방식 : 맞춘 것과 못 맞춘 것으로 나누어 전체 클래스에서 Precision을 구하는 것.\n",
    "- Recall : TP / (TP + FN) (= 예측P / 실제P)\n",
    "  - ex) Recall A = 실제 A인 것들 중 A라고 예측한 것의 비율\n",
    "  - macro, micro 방식 계산은 Precision과 동일"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c585f91d3623973be3accc48b0d5e967ce904a396a0f0c8bda7b100d8b60333f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
