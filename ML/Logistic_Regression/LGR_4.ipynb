{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "- One vs All (여기서는 이 부분을 중점적으로 다룸)\n",
    "  - m개의 class가 존재할 때, class마다 classifier 생성 \n",
    "  - softmax 기법 사용\n",
    "- One vs One\n",
    "  - 2쌍씩의 class마다 classifier를 생성, 최종 선택 시 classifier 선택을 투표를 통해 결정\n",
    "  - 총 m(m-1)/2개 만큼의 classifier 생성\n",
    "  - 정확도 up, But 속도 느려짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One vs All Approach\n",
    "  - m개의 classifier 함수 $h_m(x;\\theta)$ 생성\n",
    "  - $h_m(x;\\theta)$의 확률값 중 가장 높은 값을 가진 $m$을 선택\n",
    "  - **각 $h_m(x;\\theta)$의 확률 합이 1 이상이라는 문제점이 생김**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Softmax function for multiclass\n",
    "  - 모든 class의 확률을 1로 Generalize 함\n",
    "  > $\\sigma(z)_j = P_j = \\frac{e^{z_j}}{\\sum_{k=1}^{K}{e^{z_k}}}$ <br>\n",
    "  > $\\displaystyle\\sum_{j=1}^{K}{\\sigma(z)_j} = \\displaystyle\\sum_{j=1}^{K}{P_j} = 1$\n",
    "\n",
    "  > 여기서 $\\sigma(z)_j$ 는 probability of class $j$, $K$는 last classification class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Class가 K개일 때\n",
    "  > $\\frac{P_j}{P_K} => logit(P_j) = \\log_e(\\frac{P_j}{P_K}) = z_j = x^T\\theta_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Softmax function\n",
    "> $P_j = \\frac{e^{z_j}}{\\sum_{j=1}^{K}{e^{z_j}}} = \\frac{e^{z_j}}{\\sum_{j=1}^{K}{e^{x^T\\theta_j}}}$ $\\because z = x^T\\theta_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여기서 $\\theta_j$는 class의 개수만큼 생김\n",
    "<img src=\"./img/theta.PNG\" width=\"500px\" style=\"display:block;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 수식이 너무 길어서 패드로 필기함\n",
    "\n",
    "- Maximum Likelihood Estimation  \n",
    "<img src=\"./img/goodnote_1.jpg\" width=\"700px\" style=\"display:block;\">\n",
    "  - 위 식에서 $-\\log{L}$이 Cross Entropy\n",
    "\n",
    "- Minimize Cost Function\n",
    "<img src=\"./img/goodnote_2.jpg\" width=\"700px\" style=\"display:block;\">\n",
    "<img src=\"./img/goodnote_3.jpg\" width=\"700px\" style=\"display:block;\">\n",
    "<img src=\"./img/goodnote_4.jpg\" width=\"700px\" style=\"display:block;\">\n",
    "\n",
    "- Update weights\n",
    "<img src=\"./img/goodnote_5.jpg\" width=\"700px\" style=\"display:block;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c585f91d3623973be3accc48b0d5e967ce904a396a0f0c8bda7b100d8b60333f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
