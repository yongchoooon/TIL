{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "> $x_{new} = x_{old} - \\alpha \\times (2x_{old})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full-Batch Gradient Descent\n",
    "> $\\theta_j := \\theta_j - \\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta_0\\, \\theta_1)$ <br>\n",
    "> ${{\\partial}J\\over{\\partial}{w_0}} = \\frac{1}{m}\\sum{({{w_1}x^{(i)}}+w_0-y^{(i)})}$ <br>\n",
    "> ${{\\partial}J\\over{\\partial}{w_1}} = \\frac{1}{m}\\sum{({{w_1}x^{(i)}}+w_0-y^{(i)})x^{(i)}}$\n",
    "\n",
    "- GD는 1개의 데이터를 기준으로 미분\n",
    "- 그러나 일반적으로 GD = (full) batch GD라고 가정함.\n",
    "- **모든 데이터셋으로 학습함**\n",
    "<br>\n",
    "- 업데이트 감소 -> 계산상 효율적(속도) 가능\n",
    "- 안정적인 Cost 함수 수렴\n",
    "- 지역 최적화 가능 (전체 데이터에서 최적값을 찾지 못할 가능성 높음)\n",
    "- 메모리 문제 (ex) 30억 개의 데이터를 한번에 업데이트하면?)\n",
    "- 대규모 데이터셋에서는 모델/패러미터 업데이트가 느려짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent\n",
    "- 원래 의미는 데이터셋에서 random하게 training sample을 뽑은 후 학습할 때 사용함을 의미함.\n",
    "- Data를 넣기 전에 셔플을 먼저 함\n",
    "- 1개의 데이터씩 업데이트를 함.\n",
    "- 그렇기 때문에 빈번한 업데이트 모델 성능 및 개선 속도 확인 가능\n",
    "- 일부 문제에 대해 더 빨리 수렴 가능\n",
    "- 지역 최적화 회피 가능\n",
    "- 대용량 데이터 처리시 시간이 오래 걸림\n",
    "- 더 이상 cost가 줄어들지 않는 시점의 발견이 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Batch (Stochastic) Gradient Descent\n",
    "- 한 번에 일정량의 데이터를 랜덤하게 뽑아서 학습\n",
    "- SGD와 Full-Batch GD를 혼합한 기법\n",
    "- 가장 일반적으로 많이 쓰이는 기법\n",
    "- Epoch & Batch-size\n",
    "    - 전체 데이터가 Training 데이터에 들어갈 때 카운팅\n",
    "    - Full-batch를 n번 실행하면 n epoch\n",
    "    - Batch-size : 한 번에 학습되는 데이터의 개수\n",
    "    - ex) 총 5,120개의 Training data에 512 batch-size면 몇 번 학습을 해야 1 epoch이 되는가? => 10번"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
