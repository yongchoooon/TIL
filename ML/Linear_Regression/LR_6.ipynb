{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "- 모델이 Training data에 과다하게 최적화되어 새로운 데이터의 예측력이 떨어지는 현상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-Variance tradeoff\n",
    "- High bias : underfitting. 높은 편향. 원래 모델에 많이 떨어짐.\n",
    "    - 잘못된 데이터만 계속 학습함\n",
    "    - 잘못된 weight만 update\n",
    "- High variance : overfitting. 높은 분산. 모든 데이터에 민감하게 학습.\n",
    "    - error를 고려하지 않음\n",
    "    - 모든 weight가 update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overcoming Overfitting\n",
    "- 더 많은 데이터를 활용한다.\n",
    "    - 가장 좋은 방법이지만 현실적으로 불가능한 경우가 많음.\n",
    "- Feature의 개수를 줄인다.\n",
    "- 적절히 parameter를 선정한다.\n",
    "- Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "- weight에 penalty를 부과하여 overfitting을 방지하는 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $J(w_0, w_1) = {1\\over2m}\\displaystyle\\sum_{i=1}^{m}{(w_1x^{(i)} + w_0 - y^{(i)})^2}$\n",
    "- 위의 cost function에 $1000w_1$을 추가하여\n",
    "\n",
    "> $J(w_0, w_1) = {1\\over2m}\\displaystyle\\sum_{i=1}^{m}{(w_1x^{(i)} + w_0 - y^{(i)})^2} + 1000w_1$\n",
    "- 위의 cost function을 최소화하는 $w_1$를 찾기 위해서는, $w_1$가 조금만 커져도 $J$가 많이 커지기 때문에 $w_1$가 작아질 수 밖에 없을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
